{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd88ea27",
   "metadata": {},
   "source": [
    "<div align=\"center\" style=\" font-size: 80%; text-align: center; margin: 0 auto\">\n",
    "<img src=\"https://raw.githubusercontent.com/Explore-AI/Pictures/master/Python-Notebook-Banners/Exercise.png\"  style=\"display: block; margin-left: auto; margin-right: auto;\";/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f662d169",
   "metadata": {},
   "source": [
    "# Exercise: Advanced dimensionality reduction techniques \n",
    "Â© ExploreAI Academy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26af890c",
   "metadata": {},
   "source": [
    "In this train, we'll investigate how PCA, MDS and t-SNE dimensionality reduction techniques work on image and text data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d230d14",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Learning objectives\n",
    "\n",
    "By the end of this train, you should be able to:\n",
    "- Understand advanced dimensionality reduction techniques.\n",
    "- Implement these techniques on image and text data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de45a481",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0b7683",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Exercise 1: Principal component analysis (PCA)\n",
    "\n",
    "1. Apply PCA to the wine dataset and reduce the dimensionality to 2 components. How much variance is explained by the first two principal components?\n",
    "\n",
    "2. After applying PCA, plot the transformed data points on a scatter plot with different colours for each class. Are the classes well-separated in the reduced dimensionality space?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ee76ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "\n",
    "# insert code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9b7dc6",
   "metadata": {},
   "source": [
    "### Exercise 2: Multi-dimensional scaling (MDS) \n",
    "\n",
    "1. Apply MDS to the wine dataset and reduce the dimensionality to 2 components. What is the stress value of the MDS transformation?\n",
    "\n",
    "2. Plot the transformed data points on a scatter plot with different colors for each class. Do you observe any clusters or patterns in the reduced dimensionality space?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae48fab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert code here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4180f7ff",
   "metadata": {},
   "source": [
    "### Exercise 3: t-distributed Stochastic Neighbour Embedding (t-SNE)\n",
    "\n",
    "1. Apply t-SNE to the wine dataset and reduce the dimensionality to 2 components. How long does it take to compute the t-SNE embedding?\n",
    "\n",
    "2. Plot the transformed data points on a scatter plot with different colors for each class. What do you observe about the clusters in the reduced dimensionality space?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af5d36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555dea0d",
   "metadata": {},
   "source": [
    "## Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff8f391",
   "metadata": {},
   "source": [
    "### Exercise 1: Principal component analysis (PCA)\n",
    "\n",
    "The code below loads the wine dataset, performs PCA to reduce its dimensionality to two components, and then prints the explained variance ratio of the principal components. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad52ad95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the wine dataset\n",
    "data = load_wine()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Perform PCA\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X)\n",
    "\n",
    "# Display the explained variance ratio\n",
    "print(\"Explained variance ratio by the first two principal components: \", pca.explained_variance_ratio_)\n",
    "\n",
    "# Plot the transformed data points\n",
    "plt.figure(figsize=(8, 6))\n",
    "for i in range(len(set(y))):\n",
    "    plt.scatter(X_pca[y == i, 0], X_pca[y == i, 1], label=f'Class {i}')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.title('PCA on Wine Dataset')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e586ae6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1fbdb88a",
   "metadata": {},
   "source": [
    "**Output explained:**\n",
    "\n",
    "The output `[0.99809123 0.00173592]` indicates that the first principal component explains about 99.81% of the variance, while the second explains about 0.17%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10363b6",
   "metadata": {},
   "source": [
    "### Exercise 2: Multi-dimensional scaling (MDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09386d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "from sklearn.manifold import MDS\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the wine dataset\n",
    "data = load_wine()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Perform MDS\n",
    "mds = MDS(n_components=2, random_state=42)\n",
    "X_mds = mds.fit_transform(X)\n",
    "\n",
    "# Display the stress value\n",
    "print(\"Stress value of the MDS transformation: \", mds.stress_)\n",
    "\n",
    "# Plot the transformed data points\n",
    "plt.figure(figsize=(8, 6))\n",
    "for i in range(len(set(y))):\n",
    "    plt.scatter(X_mds[y == i, 0], X_mds[y == i, 1], label=f'Class {i}')\n",
    "plt.xlabel('MDS Dimension 1')\n",
    "plt.ylabel('MDS Dimension 2')\n",
    "plt.title('MDS on Wine Dataset')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff325262",
   "metadata": {},
   "source": [
    "**Output explanation:**\n",
    "\n",
    "1. **Stress value of the MDS transformation**:\n",
    "   The stress value is a measure of how well the distances between data points in the original high-dimensional space are preserved in the reduced-dimensional space.\n",
    "\n",
    "   While we know that the stress metric is better if lower, we cannot clearly interpret the stress value for the metric version of MDS based on value alone - it's more likely to be a comparison. This value isn't normalised, as it's metric rather than non-metric (where we want to see results between +-0 and 0.2) [In summary, when interpreting stress values from the metric version of MDS, aim for lower values compared to a random configuration of the same data. While there isn't an absolute threshold, lower stress values relative to this baseline indicate a better fit of the chosen dimensions to the original data.]\n",
    "\n",
    "   In this case, the stress value of approximately `19573.00` suggests that the MDS transformation does not have a high accuracy in preserving the pairwise distances between data points.\n",
    "\n",
    "2. **Observations from the plot**:\n",
    "\n",
    "   Observing clusters or patterns in the reduced dimensionality space involves looking for groups of points that are close together or exhibit similar arrangements across the plot. However, with the current settings and parameters, it is not entirely clear how the points are grouped. While some patterns are present, there are no distinct delineations, and the points are not spread out very well. This suggests that the current representation might not be optimal and further adjustments may be necessary to achieve clearer clustering.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3674b1f9",
   "metadata": {},
   "source": [
    "### Exercise 3: t-distributed Stochastic Neighbour Embedding (t-SNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32bd3d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "# Load the wine dataset\n",
    "data = load_wine()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Perform t-SNE\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "start_time = time.time()\n",
    "X_tsne = tsne.fit_transform(X)\n",
    "end_time = time.time()\n",
    "\n",
    "# Display the time taken\n",
    "print(\"Time taken to compute t-SNE embedding: \", end_time - start_time, \" seconds\")\n",
    "\n",
    "# Plot the transformed data points\n",
    "plt.figure(figsize=(8, 6))\n",
    "for i in range(len(set(y))):\n",
    "    plt.scatter(X_tsne[y == i, 0], X_tsne[y == i, 1], label=f'Class {i}')\n",
    "plt.xlabel('t-SNE Dimension 1')\n",
    "plt.ylabel('t-SNE Dimension 2')\n",
    "plt.title('t-SNE on Wine Dataset')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a71d54",
   "metadata": {},
   "source": [
    "**Output Explanation:**\n",
    "\n",
    "The plot shows the distribution of the wine dataset into three classes (0, 1, 2), each represented by a different colour. t-SNE has effectively grouped similar data points, indicating it's useful for visualising high-dimensional data in two dimensions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26fd094b-0fee-46f1-a4b8-73766813c42b",
   "metadata": {
    "tags": []
   },
   "source": [
    "#  \n",
    "\n",
    "<div align=\"center\" style=\" font-size: 80%; text-align: center; margin: 0 auto\">\n",
    "<img src=\"https://raw.githubusercontent.com/Explore-AI/Pictures/master/ExploreAI_logos/EAI_Blue_Dark.png\"  style=\"width:200px\";/>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
